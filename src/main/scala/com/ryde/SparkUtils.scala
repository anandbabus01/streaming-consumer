import org.apache.spark.SparkConf

class SparkUtils {
def getSparkConfiguration()

  val conf: SparkConf = new SparkConf().setAppName(Constants.SPARK_APP_NAME).set(Constants.CASSANDRA_HOST_FORMAT, Constants.CASSANDRA_HOST).set(Constants.SPARK_CASSANDRA_CONNECTION_TIMEOUT_MS_PROP, Constants.SPARK_CASSANDRA_CONNECTION_TIMEOUT_MS).set(Constants.SPARK_CASSANDRA_FETCH_SIZE_IN_ROWS_PROP, Constants.SPARK_CASSANDRA_FETCH_SIZE_IN_ROWS).set(Constants.SPARK_CASSANDRA_KEEP_ALIVE_MS_PROP, Constants.SPARK_CASSANDRA_KEEP_ALIVE_MS).set(Constants.SPARK_CASSANDRA_CONNS_PER_EXECUTOR_MAX_PROP, Constants.SPARK_CASSANDRA_CONNS_PER_EXECUTOR_MAX).set(Constants.SPARK_CASSANDRA_CONN_COMPRESSION_TYPE_PROP, Constants.SPARK_CASSANDRA_CONN_COMPRESSION_TYPE).set(Constants.SPARK_CASSANDRA_OUTPUT_IGNORENULLS_PROP, Constants.SPARK_CASSANDRA_OUTPUT_IGNORENULLS).set(Constants.SPARK_CASSANDRA_OUTPUT_CONCURRENT_WRITES_PROP, Constants.SPARK_CASSANDRA_OUTPUT_CONCURRENT_WRITES).set(Constants.SPARK_CASSANDRA_OUTPUT_THROUGHPUT_MB_SEC_PROP, Constants.SPARK_CASSANDRA_OUTPUT_THROUGHPUT_MB_SEC).set(Constants.SPARK_CASSANDRA_OUTPUT_BATCH_SIZE_BYTES_PROP, Constants.SPARK_CASSANDRA_OUTPUT_BATCH_SIZE_BYTES).set(Constants.SPARK_CASSANDRA_OUTPUT_BATCH_SIZE_ROWS_PROP, Constants.SPARK_CASSANDRA_OUTPUT_BATCH_SIZE_ROWS).set(Constants.SPARK_CASSANDRA_OUTPUT_METRICS_PROP, Constants.SPARK_CASSANDRA_OUTPUT_METRICS).set //.set(Constants.SPARK_CASSANDRA_OUTPUT_CONSISTENCY_LEVEL_PROP, Constants.SPARK_CASSANDRA_OUTPUT_CONSISTENCY_LEVEL)
  (Constants.SPARK_STREAMING_BACKPRESSURE_ENABLED_PROP, Constants.SPARK_STREAMING_BACKPRESSURE_ENABLED).set(Constants.SPARK_STREAMING_CONCURRENT_JOBS_PROP, Constants.SPARK_STREAMING_CONCURRENT_JOBS)
  conf = conf.setMaster(Constants.SPARK_MASTER)
  conf.set("spark.scheduler.mode", Constants.SPARK_SCHEDULER_MODE)
  return conf


}
